% !TEX encoding = UTF-8 Unicode
\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage[slovene,english]{babel}
\usepackage{erk}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[top=22.5mm, bottom=22.5mm, left=22.5mm, right=22.5mm]{geometry}
\usepackage{hyperref}

% lokalne definicije
\def\footnotemark{} % da se izognemo opombi na naslovnici (erk.sty trik)

\title{Poročilo prve laboratorijske vaje pri predmetu Informacija in kodi}

\author{Rok Prezelj
}

\affiliation{Univerza v Ljubljani, Fakulteta za elektrotehniko}

\email{E-pošta: rp0067@student.uni-lj.si}

\begin{document}

\maketitle

\begin{abstract}
\noindent\textbf{Povzetek.}
Laboratorijska vaja je bila namenjena analizi različnih datotek, pri čemer se je določila verjetnost pojavljanja 8-bitnih znakov in na njihovi podlagi izračunali entropijo informacijskega vira pri različni dolžini nizov.
\end{abstract}

\selectlanguage{slovene}

\section{Uvod}
Entropija je merilo nedoločenosti naključnih sistemov, večja kot je, bolj je sistem nepredvidljiv~\cite{Entropija}. V informacijski teoriji predstavlja entropija povprečno količino informacije, ki jo vsebuje posamezen simbol vira, in nam omogoča oceno učinkovitosti kodiranja ter stopnje naključnosti v podatkih~\cite{ucbenik}.

\section{Metodologija}
V okviru naloge smo implementirali program za analizo datotek in izračun entropije za različne dolžine nizov \cite{github}. Program prebere binarno vsebino izbranih datotek in prešteje pojavljanja vseh možnih kombinacij $n$-bajtnih nizov. Nato izračuna verjetnost ter entropijo po formuli:
\begin{equation}
H_n(X) = - \frac{1}{n}\sum_{i} p_i \log_2 p_i,
\label{en_Entropija}
\end{equation}

kjer je $p_i$ verjetnost posameznega niza, $n$ dolžina nizov v bajtih za $n = [1, 5]$.

\section{Rezultati}
Z formulo~\eqref{en_Entropija} smo analizirali različne oblike podatkov in opazili, da se z višanjem dolžine niza entropija manjša.

\subsection{Besedilne datoteke}
Za datoteko \texttt{besedilo.txt} se entropija od $H_1 = 4.57$ zniža do $H_5 = 3.03$.
To pomeni, da ima besedilo precejšnjo redundanco, torej določeni znaki in kombinacije se pojavljajo bistveno pogosteje kot drugi.
Takšna odvisnost je posledica jezikovne strukture (črke, presledki, pogosti nizi znakov), kar omogoča zelo učinkovito brezizgubno kompresijo (npr. ZIP~\cite{ZIP}, Huffman~\cite{Huff}, LZW~\cite{LZW}).

\subsection{Zvočni posnetki}
Zvočne datoteke v surovih formatih (\texttt{.wav}, \texttt{.aiff}, \texttt{.raw}) imajo skoraj enake entropije:
\[
H_1 \approx 6.35, \quad H_5 \approx 4.27.
\]
To pomeni, da vse tri vsebinsko hranijo iste vzorce in da zaglavje (header) pri WAV ali AIFF nima bistvenega vpliva.

Pri kompresiranih oblikah (\texttt{.flac}, \texttt{.m4a}, \texttt{.mp3}, \texttt{.ogg}) pa opazimo naslednje:

\textit{\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Format} & $H_1$ & $H_5$\\
\hline
WAV / RAW / AIFF & 6.35 & 4.27 \\
FLAC & 7.95 & 4.74  \\
M4A & 7.97 & 4.75  \\
MP3 & 7.93 & 4.46  \\
OGG & 7.98 & 4.22  \\
\hline
\end{tabular}
\caption{Entropije zvočnih posnetkov v različnih formatih.}
\end{table}}

Pri formatu OGG, ki je definiran v standardu rfc3533~\cite{rfc3533}, opazimo, da ima $H_1$ skoraj maksimalno vrednost, kar potrjuje učinkovito odstranitev redundance med posameznimi bajti.
Kljub temu pa ima $H_5$ nekoliko nižjo vrednost kot nekompresirani formati, kar kaže na prisotnost ponavljajočih se struktur v kodnem zapisu (paketno kodiranje, zaglavja, metapodatki).
Takšne periodične vzorce algoritmi kompresije vnesejo zaradi organizacije podatkov, ne zaradi vsebinske redundance.
\\

Na slikah~\ref{fig:verjetnostiAiff}~in~\ref{fig:verjetnostiMp3} sta prikazani porazdelitvi verjetnosti posameznih bajtov
v nekompresiranem (\texttt{AIFF/RAW/WAV}) in kompresiranem (\texttt{MP3}) zvočnem zapisu.
Pri formatu \texttt{AIFF} je opazna značilna oblika črke \emph{U}, saj prevladujeta vrednosti bajtov \texttt{0x00} in \texttt{0xFF}.
To nakazuje, da v zapisu pogosto nastopajo vzorci z nizkimi ali visokimi amplitudami, kar je značilno za \emph{PCM}-kodiranje~\cite{PCM},
kjer vrednosti neposredno predstavljajo amplitudo signala.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{verjetnostNizovAiff.png}
\caption{Porazdelitev verjetnosti bajtov v nekompresiranem zapisu \texttt{AIFF}.
Značilna oblika črke \emph{U} kaže na pogosti vrednosti \texttt{0x00} in \texttt{0xFF}.}
\label{fig:verjetnostiAiff}
\end{figure}

Pri formatu \texttt{MP3} je porazdelitev verjetnosti bajtov bolj enakomerna in ima žagasto obliko.
To je posledica izgubne kompresije, kjer se signal pred shranjevanjem pretvori v frekvenčno obliko in del podatkov zavrže.
Zaradi tega so bolj naključni, kar pomeni večjo entropijo in učinkovitejše kodiranje.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{verjetnostNizovMp3.png}
\caption{Porazdelitev verjetnosti bajtov v kompresiranem zapisu \texttt{MP3}.
Žagasta oblika porazdelitve je posledica izgubne kompresije.}
\label{fig:verjetnostiMp3}
\end{figure}

Kompresirani formati imajo pri $H_1$ višje vrednosti (bližje 8 bitov/simbol), kar pomeni, da so bajti po kodiranju statistično bolj enakomerno porazdeljeni, kar pomeni, da datoteka vsebuje manj ponavljajočih se vzorcev.

\subsection{Slikovne datoteke}
Pri analizi slike je bil uporabljen enak format (\texttt{jpg}), vendar se je spreminjala velikost fotografije po ločljivosti. Za njih smo izračunali entropijo pri različni dolžini niza. Uporabljena fotografija je vidna na sliki~\ref{fig:iss}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{iss_7680.jpg}
    \caption{Fotografija Mednarodne vesoljske postaje (ISS), uporabljena pri analizi entropije slikovnih podatkov.}
    \label{fig:iss}
\end{figure}

Iz tabele je razvidno, da se pri vseh slikah vrednost $H_1$ nahaja blizu 8 bitov, kar pomeni, da so posamezni bajti v JPEG zapisu skoraj enakomerno porazdeljeni.
Pri višjih členih ($H_3$–$H_5$) pa entropija narašča z ločljivostjo slike:
manjše slike (npr. \texttt{iss\_0480.jpg}) imajo bolj izrazite ponavljajoče se vzorce in zato nižjo entropijo, medtem ko večje slike (npr. \texttt{iss\_7680.jpg}) vsebujejo več detajlov in lokalnih variacij, kar vodi do višje entropije. S tem je potrjeno, da večja prostorska kompleksnost slike povzroči večjo informacijsko vsebino.

\begin{table}
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Datoteka} & \textbf{Ločljivost [px]} & \textbf{Velikost datoteke} \\
\hline
iss\_0480.jpg & 480 $\times$ 270 & 32~kB \\
iss\_0960.jpg & 960 $\times$ 540 & 92~kB \\
iss\_1920.jpg & 1920 $\times$ 1080 & 220~kB \\
iss\_2560.jpg & 2560 $\times$ 1440 & 320~kB \\
iss\_3840.jpg & 3840 $\times$ 2160 & 528~kB \\
iss\_7680.jpg & 7680 $\times$ 4320 & 12~MB \\
\hline
\end{tabular}
\caption{Velikosti in ločljivosti JPEG slik ISS uporabljenih pri analizi entropije. Z večanjem ločljivosti raste tako število pikslov kot velikost datoteke, saj vsebuje več informacijskih vzorcev in posledično višjo entropijo.}
\end{table}

\begin{table}
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Datoteka} & $H_1$ & $H_2$ & $H_3$ & $H_4$ & $H_5$ \\
\hline
iss\_0480.jpg & 7.97 & 7.18 & 4.97 & 3.73 & 2.98 \\
iss\_0960.jpg & 7.95 & 7.57 & 5.47 & 4.11 & 3.29 \\
iss\_1920.jpg & 7.97 & 7.74 & 5.88 & 4.43 & 3.55 \\
iss\_2560.jpg & 7.96 & 7.75 & 6.02 & 4.55 & 3.65 \\
iss\_3840.jpg & 7.86 & 7.64 & 6.15 & 4.69 & 3.77 \\
iss\_7680.jpg & 7.99 & 7.93 & 7.53 & 5.88 & 4.71 \\
\hline
\end{tabular}
\caption{Izračunane vrednosti entropij ($H_1$–$H_5$) za JPEG slike ISS pri različnih ločljivostih. Z večanjem velikosti slike naraščajo tudi višje entropije ($H_3$–$H_5$), kar nakazuje večjo kompleksnost in manjšo korelacijo med zaporednimi bajti.}
\end{table}


\section{Povzetek}
\begin{itemize}
    \item Z naraščajočim $n$ entropija pada pri vseh vrstah datotek, kar potrjuje prisotnost statistične odvisnosti.
    \item Besedilo ima najmanjšo entropijo zaradi jezikovne strukture in visoke redundance.
    \item Zvočni signali imajo srednjo entropijo, kompresija pa zmanjša redundanco.
    \item Slikovni podatki so najbližje naključnim (pri $H_1 \approx 8$), saj JPEG učinkovito porazdeli bite.
    \item Večja ločljivost slike poveča entropijo pri višjih $n$, ker raste količina unikatnih lokalnih vzorcev.
\end{itemize}

\small
\begin{thebibliography}{1}

\bibitem{Entropija}
Wikipedia, \emph{Entropy (information theory)}.
[Na spletu]. Dostopno na: \url{https://en.wikipedia.org/wiki/Entropy_(information_theory)}
[Dostopano: 8. november 2025].

\bibitem{ucbenik}
N. Pavešić, \emph{Informacija in kodi}, 2. spremenjena in dopolnjena izdaja.
Ljubljana: Založba Fakultete za elektrotehniko in Fakultete za računalništvo in informatiko, 2010.
ISBN 978-961-243-145-7.
[Na spletu]. Dostopno na: \url{https://plus.cobiss.net/cobiss/si/sl/data/cobib/250590208}

\bibitem{github}
R. Prezelj, \emph{GitHub repozitorij}, 2025.
[Na spletu]. Dostopno na: \url{https://github.com/RokPre/informacija-in-kodi}

\bibitem{ZIP}
Spiceworks, "What Is a ZIP File? Meaning, Working, and Advantages",
\emph{Tech Encyclopedia}, 2024.
[Na spletu]. Dostopno na: \url{https://www.spiceworks.com/tech/tech-general/articles/what-is-zip-file/}

\bibitem{LZW}
T. A. Welch, "A Technique for High-Performance Data Compression",
\emph{Computer}, letn. 17, št. 6, str. 8–19, jun. 1984.
doi: \href{https://doi.org/10.1109/MC.1984.1659158}{10.1109/MC.1984.1659158}

\bibitem{Huff}
D. A. Huffman, "A Method for the Construction of Minimum-Redundancy Codes",
\emph{Proceedings of the IRE}, letn. 40, št. 9, str. 1098–1101, sep. 1952.
doi: \href{https://doi.org/10.1109/JRPROC.1952.273898}{10.1109/JRPROC.1952.273898}

\bibitem{rfc3533}
S. Pfeiffer, "The Ogg Encapsulation Format Version 0",
\emph{IETF RFC 3533}, maj 2003.
[Na spletu]. Dostopno na: \url{https://www.rfc-editor.org/rfc/rfc3533}

\bibitem{PCM}
Wikipedia, \emph{Pulse-code modulation}.
[Na spletu]. Dostopno na: \url{https://en.wikipedia.org/wiki/Pulse-code_modulation}
[Dostopano: 8. november 2025].


\end{thebibliography}

\end{document}
